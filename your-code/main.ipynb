{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some web scraping exercises to practice your scraping skills using `requests` and `Beautiful Soup`.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the [response status code](https://http.cat/) for each request to ensure you have obtained the intended content.\n",
    "- Look at the HTML code in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract.\n",
    "- Check out the css selectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Resources\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all, gathering our tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ **Again, please remember to limit your output before submission so that your code doesn't get lost in the output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 1 - Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">\\n\\n\\n\\n  <link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-k9NM/a2xYY6wCRcWG7f3ROm4X5CJNikViGX0N8YIxs6sUYAe/j08/RSHXr3fA9wLIy87AMFCgXm6jbvhZhIXWw==\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/frameworks-93d34cfdadb1618eb00917161bb7f744.css\" />\\n  <link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-ZUf6K+vQqMY+RhVzaRmCy2ePbSZad4TkaGRbd6v5gFt6f9Q/nqjDkBDjQgXNmZw7J9mcYxlsE4fhRw7CTluRow==\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/site-6547fa2bebd0a8c63e461573691982cb.css\" />\\n    <link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-mm2SigzEudA9xS8nyiKvpPVLuATFJopEhsZReSWJTn'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below (with different names):\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nombres:\n",
    "dev_names_tags = soup.select(\"h1.h3.lh-condensed\")\n",
    "len(dev_names_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"h3 lh-condensed\">\n",
       "<a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":928116,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"25015dfe1247ba4a6f212624be2a96d03de5b86131b98d7c372384c98be9e8c5\" href=\"/mlocati\">\n",
       "            Michele Locati\n",
       "</a> </h1>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_names_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michele Locati'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_names_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [(i.text.strip()) for i in dev_names_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Michele Locati',\n",
       " 'Han Xiao',\n",
       " 'Alon Zakai',\n",
       " 'Ha Thach',\n",
       " 'Joel Arvidsson',\n",
       " 'Major Hayden',\n",
       " 'Ahmet Alp Balkan',\n",
       " 'Don Jayamanne',\n",
       " 'Alexey Golub',\n",
       " 'Diego Muracciole',\n",
       " 'Simen Bekkhus',\n",
       " 'Dan Davison',\n",
       " 'Mo Gorhom',\n",
       " 'José Padilla',\n",
       " 'Yevgeniy Brikman',\n",
       " 'Thibault Duplessis',\n",
       " 'Nelson Osacky',\n",
       " 'Gleb Bahmutov',\n",
       " 'Soledad Galli',\n",
       " 'Gerasimos (Makis) Maropoulos',\n",
       " 'Nicolas P. Rougier',\n",
       " 'snipe',\n",
       " 'Anthony Sottile',\n",
       " 'Julius Härtl',\n",
       " 'Samuel Colvin']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nicks\n",
    "dev_names_tags = soup.select(\"p.f4.text-normal.mb-1\")\n",
    "len(dev_names_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlocati'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_names_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicks = [(i.text.strip()) for i in dev_names_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlocati',\n",
       " 'hanxiao',\n",
       " 'kripken',\n",
       " 'hathach',\n",
       " 'oblador',\n",
       " 'major',\n",
       " 'ahmetb',\n",
       " 'DonJayamanne',\n",
       " 'Tyrrrz',\n",
       " 'diegomura',\n",
       " 'SimenB',\n",
       " 'dandavison',\n",
       " 'gorhom',\n",
       " 'jpadilla',\n",
       " 'brikis98',\n",
       " 'ornicar',\n",
       " 'runningcode',\n",
       " 'bahmutov',\n",
       " 'solegalli',\n",
       " 'kataras',\n",
       " 'rougier',\n",
       " 'snipe',\n",
       " 'asottile',\n",
       " 'juliushaertl',\n",
       " 'samuelcolvin']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_nick = tuple(zip(names,nicks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Michele Locati', 'mlocati'),\n",
       " ('Han Xiao', 'hanxiao'),\n",
       " ('Alon Zakai', 'kripken'),\n",
       " ('Ha Thach', 'hathach'),\n",
       " ('Joel Arvidsson', 'oblador'),\n",
       " ('Major Hayden', 'major'),\n",
       " ('Ahmet Alp Balkan', 'ahmetb'),\n",
       " ('Don Jayamanne', 'DonJayamanne'),\n",
       " ('Alexey Golub', 'Tyrrrz'),\n",
       " ('Diego Muracciole', 'diegomura'),\n",
       " ('Simen Bekkhus', 'SimenB'),\n",
       " ('Dan Davison', 'dandavison'),\n",
       " ('Mo Gorhom', 'gorhom'),\n",
       " ('José Padilla', 'jpadilla'),\n",
       " ('Yevgeniy Brikman', 'brikis98'),\n",
       " ('Thibault Duplessis', 'ornicar'),\n",
       " ('Nelson Osacky', 'runningcode'),\n",
       " ('Gleb Bahmutov', 'bahmutov'),\n",
       " ('Soledad Galli', 'solegalli'),\n",
       " ('Gerasimos (Makis) Maropoulos', 'kataras'),\n",
       " ('Nicolas P. Rougier', 'rougier'),\n",
       " ('snipe', 'snipe'),\n",
       " ('Anthony Sottile', 'asottile'),\n",
       " ('Julius Härtl', 'juliushaertl'),\n",
       " ('Samuel Colvin', 'samuelcolvin'))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_nick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Challenge 2 - Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url2 = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">\\n\\n\\n\\n  <link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-k9NM/a2xYY6wCRcWG7f3ROm4X5CJNikViGX0N8YIxs6sUYAe/j08/RSHXr3fA9wLIy87AMFCgXm6jbvhZhIXWw==\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/frameworks-93d34cfdadb1618eb00917161bb7f744.css\" />\\n  <link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-ZUf6K+vQqMY+RhVzaRmCy2ePbSZad4TkaGRbd6v5gFt6f9Q/nqjDkBDjQgXNmZw7J9mcYxlsE4fhRw7CTluRow==\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/site-6547fa2bebd0a8c63e461573691982cb.css\" />\\n    <link crossorigin=\"anonymous\" media=\"all\" integrity=\"sha512-mm2SigzEudA9xS8nyiKvpPVLuATFJopEhsZReSWJTn'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names = soup.select(\"h1.h3.lh-condensed\")\n",
    "len(repo_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1 class=\"h3 lh-condensed\">\n",
       "<a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_REPOSITORIES_PAGE\",\"click_target\":\"REPOSITORY\",\"click_visual_representation\":\"REPOSITORY_NAME_HEADING\",\"actor_id\":null,\"record_id\":240315046,\"originating_url\":\"https://github.com/trending/python?since=daily\",\"user_id\":null}}' data-hydro-click-hmac=\"4e4ae9fe56c93d4b1c3c4d96b377380b68f4727741403591b8b5bc5ee5cc0575\" href=\"/jina-ai/jina\">\n",
       "<svg aria-hidden=\"true\" class=\"octicon octicon-repo mr-1 text-gray\" height=\"16\" version=\"1.1\" viewbox=\"0 0 16 16\" width=\"16\"><path d=\"M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z\" fill-rule=\"evenodd\"></path></svg>\n",
       "<span class=\"text-normal\">\n",
       "        jina-ai /\n",
       "</span>\n",
       "      jina\n",
       "</a> </h1>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jina-ai /\\n\\n      jina'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jina-ai       jina'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names[0].text.strip().replace(\"\\n\",\"\").replace(\"/\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_names_ok = [(i).text.strip().replace(\"\\n\",\"\").replace(\"/\",\"\") for i in repo_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jina-ai       jina',\n",
       " 'MTK-bypass       bypass_utility',\n",
       " 'ansible       awx',\n",
       " 'Asabeneh       30-Days-Of-Python',\n",
       " 'PaddlePaddle       PaddleOCR',\n",
       " 'RyanElliott10       wsbtickerbot',\n",
       " 'facebookresearch       detectron2',\n",
       " 'public-apis       public-apis',\n",
       " 'huggingface       transformers',\n",
       " 'OWASP       CheatSheetSeries',\n",
       " 'demisto       content',\n",
       " 'pandas-dev       pandas',\n",
       " 'facebookresearch       ParlAI',\n",
       " 'facebookresearch       detr',\n",
       " 'pytorch       vision',\n",
       " 'wagtail       wagtail',\n",
       " 'great-expectations       great_expectations',\n",
       " 'sanic-org       sanic',\n",
       " 'pytorch       fairseq',\n",
       " 'mingrammer       diagrams',\n",
       " 'nodejs       node-gyp',\n",
       " 'deepfakes       faceswap',\n",
       " 'Vonng       ddia',\n",
       " 'spulec       moto',\n",
       " 'samuelcolvin       pydantic']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_names_ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 3 - Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url3 = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url3)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = soup.select(\"a.image\")\n",
    "len(wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"image\" href=\"/wiki/File:Walt_Disney_1946.JPG\"><img alt=\"Walt Disney 1946.JPG\" data-file-height=\"675\" data-file-width=\"450\" decoding=\"async\" height=\"330\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/330px-Walt_Disney_1946.JPG 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/440px-Walt_Disney_1946.JPG 2x\" width=\"220\"/></a>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/File:Walt_Disney_1946.JPG'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd[0].get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(wd_images.append(i.get(\"href\"))for i in wd) # lo he intentado de esta forma y no me sale..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_images = []\n",
    "for i in wd:\n",
    "    wd_images.append(i.get(\"href\"))\n",
    "len(wd_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/File:Walt_Disney_1946.JPG',\n",
       " '/wiki/File:Walt_Disney_1942_signature.svg',\n",
       " '/wiki/File:Walt_Disney_envelope_ca._1921.jpg',\n",
       " '/wiki/File:Trolley_Troubles_poster.jpg',\n",
       " '/wiki/File:Walt_Disney_and_his_cartoon_creation_%22Mickey_Mouse%22_-_National_Board_of_Review_Magazine.jpg',\n",
       " '/wiki/File:Steamboat-willie.jpg',\n",
       " '/wiki/File:Walt_Disney_1935.jpg',\n",
       " '/wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg',\n",
       " '/wiki/File:Disney_drawing_goofy.jpg',\n",
       " '/wiki/File:DisneySchiphol1951.jpg',\n",
       " '/wiki/File:WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '/wiki/File:Walt_disney_portrait_right.jpg',\n",
       " '/wiki/File:Walt_Disney_Grave.JPG',\n",
       " '/wiki/File:Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " '/wiki/File:Disney_Display_Case.JPG',\n",
       " '/wiki/File:Disney1968.jpg',\n",
       " '/wiki/File:Animation_disc.svg',\n",
       " '/wiki/File:P_vip.svg',\n",
       " '/wiki/File:Magic_Kingdom_castle.jpg',\n",
       " '/wiki/File:Video-x-generic.svg',\n",
       " '/wiki/File:Flag_of_Los_Angeles_County,_California.svg',\n",
       " '/wiki/File:Blank_television_set.svg',\n",
       " '/wiki/File:Flag_of_the_United_States.svg']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 4 - Retrieve all links to pages on Wikipedia that refer to some kind of Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url4 ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Python - Wikipedia</title>\\n<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":!1,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"YBMk-QpAMNYAAC13qa8AAAAA\",\"wgCSPNonce\":!1,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":!1,\"wgNamespaceNumber\":0,\"wgPageName\":\"Python\",\"wgTitle\":\"Python\",\"wgCurRevisionId\":997582414,\"wgRevisionId\":997582414,\"wgArticleId\":46332325,\"wgIsArticle\":!0,\"wgIsRedirect\":!1,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Disambiguation pages with short descriptions\",\"Short description is different from Wikidata\",\"All article disambiguation pages\",\"All disambiguation pages\",\"Animal common name disambiguation pages\",\"Dis'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_pages = soup.select(\"div.mw-parser-output ul li a\") \n",
    "len(py_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"mw-redirect\" href=\"/wiki/Pythons\" title=\"Pythons\">Pythons</a>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_lista = []\n",
    "var = \"\"\n",
    "for i in py_pages:\n",
    "    if \"#\" in i:\n",
    "        var.append(i)\n",
    "    else:\n",
    "        py_lista.append(i.get(\"href\"))\n",
    "len(py_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Pythons',\n",
       " '/wiki/Python_(genus)',\n",
       " '#Computing',\n",
       " '#People',\n",
       " '#Roller_coasters',\n",
       " '#Vehicles',\n",
       " '#Weaponry',\n",
       " '#Other_uses',\n",
       " '#See_also',\n",
       " '/wiki/Python_(programming_language)',\n",
       " '/wiki/CMU_Common_Lisp',\n",
       " '/wiki/PERQ#PERQ_3',\n",
       " '/wiki/Python_of_Aenus',\n",
       " '/wiki/Python_(painter)',\n",
       " '/wiki/Python_of_Byzantium',\n",
       " '/wiki/Python_of_Catana',\n",
       " '/wiki/Python_Anghelo',\n",
       " '/wiki/Python_(Efteling)',\n",
       " '/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " '/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " '/wiki/Python_(automobile_maker)',\n",
       " '/wiki/Python_(Ford_prototype)',\n",
       " '/wiki/Python_(missile)',\n",
       " '/wiki/Python_(nuclear_primary)',\n",
       " '/wiki/Colt_Python',\n",
       " '/wiki/PYTHON',\n",
       " '/wiki/Python_(film)',\n",
       " '/wiki/Python_(mythology)',\n",
       " '/wiki/Monty_Python',\n",
       " '/wiki/Python_(Monty)_Pictures',\n",
       " '/wiki/Cython',\n",
       " '/wiki/Pyton',\n",
       " '/wiki/Pithon']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_lista # me salen los \"#\" y no sé cómo quitarlo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 5 - Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url5 = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\\'1.0\\' encoding=\\'UTF-8\\' ?>\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>\\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=8\" />\\n        <meta http-equiv=\"pragma\" content=\"no-cache\" /><!-- HTTP 1.0 -->\\n        <meta http-equiv=\"cache-control\" content=\"no-cache,must-revalidate\" /><!-- HTTP 1.1 -->\\n        <meta http-equiv=\"expires\" content=\"0\" />\\n        <link rel=\"shortcut icon\" href=\"/javax.faces.resource/favicon.ico.xhtml?ln=images\" /><link type=\"text/css\" rel=\"stylesheet\" href=\"/javax.faces.resource/cssLayout.css.xhtml?ln=css\" /><script type=\"text/javascript\" src=\"/javax.faces.resource/jsf.js.xhtml?ln=javax.faces\"></script><link type=\"text/css\" rel=\"stylesheet\" href=\"/javax.faces.resource/static.css.xhtml?ln=css\" /></head><body><script type=\"text/javascript\" src=\"/'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = soup.select(\"div.usctitlechanged\")\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title 6 - Domestic Security'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 6 - Domestic Security',\n",
       " 'Title 10 - Armed Forces ٭',\n",
       " 'Title 15 - Commerce and Trade',\n",
       " 'Title 20 - Education',\n",
       " 'Title 28 - Judiciary and Judicial Procedure ٭',\n",
       " 'Title 31 - Money and Finance ٭',\n",
       " 'Title 33 - Navigation and Navigable Waters',\n",
       " 'Title 36 - Patriotic and National Observances, Ceremonies, and Organizations ٭',\n",
       " 'Title 37 - Pay and Allowances of the Uniformed Services ٭',\n",
       " \"Title 38 - Veterans' Benefits ٭\",\n",
       " 'Title 40 - Public Buildings, Property, and Works ٭',\n",
       " 'Title 46 - Shipping ٭']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i.text.strip())for i in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ttchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 6 - A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url6 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html lang=\"en\" data-gridsystem=\"bs3\">\\n<head>\\n<meta charset=\"utf-8\">\\n<meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\\n<link rel=\"canonical\" href=\"https://www.fbi.gov/wanted/topten\"><meta name=\"twitter:card\" content=\"summary_large_image\">\\n<meta name=\"twitter:title\" content=\"Ten Most Wanted Fugitives | Federal Bureau of Investigation\">\\n<meta property=\"og:site_name\" content=\"Federal Bureau of Investigation\">\\n<meta property=\"og:title\" content=\"Ten Most Wanted Fugitives | Federal Bureau of Investigation\">\\n<meta property=\"og:type\" content=\"website\">\\n<meta name=\"twitter:site\" content=\"@FBI\">\\n<meta property=\"og:article:publisher\" content=\"https://www.facebook.com/FBI\">\\n<meta name=\"twitter:description\" content=\"The FBI is offering rewards for information leading to the apprehension of the Ten Most Wanted Fugitives. Select the images of suspects to display more information.\">\\n<meta name=\"twitter:url\" cont'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topten = soup.select(\"h3 a\")\n",
    "len(topten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.fbi.gov/wanted/topten/alejandro-castillo\">ALEJANDRO ROSALES CASTILLO</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/arnoldo-jimenez\">ARNOLDO JIMENEZ</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/jason-derek-brown\">JASON DEREK BROWN</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/alexis-flores\">ALEXIS FLORES</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/jose-rodolfo-villarreal-hernandez\">JOSE RODOLFO VILLARREAL-HERNANDEZ</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/eugene-palmer\">EUGENE PALMER</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/rafael-caro-quintero\">RAFAEL CARO-QUINTERO</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/robert-william-fisher\">ROBERT WILLIAM FISHER</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/bhadreshkumar-chetanbhai-patel\">BHADRESHKUMAR CHETANBHAI PATEL</a>,\n",
       " <a href=\"https://www.fbi.gov/wanted/topten/yaser-abdel-said\">YASER ABDEL SAID</a>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALEJANDRO ROSALES CASTILLO'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topten[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALEJANDRO ROSALES CASTILLO',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'EUGENE PALMER',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'YASER ABDEL SAID']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.text.strip()for i in topten]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 7 - List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url7 = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html lang=\"mul\" class=\"no-js\">\\n<head>\\n<meta charset=\"utf-8\">\\n<title>Wikipedia</title>\\n<meta name=\"description\" content=\"Wikipedia is a free online encyclopedia, created and edited by volunteers around the world and hosted by the Wikimedia Foundation.\">\\n<script>\\ndocument.documentElement.className = document.documentElement.className.replace( /(^|\\\\s)no-js(\\\\s|$)/, \"$1js-enabled$2\" );\\n</script>\\n<meta name=\"viewport\" content=\"initial-scale=1,user-scalable=yes\">\\n<link rel=\"apple-touch-icon\" href=\"/static/apple-touch/wikipedia.png\">\\n<link rel=\"shortcut icon\" href=\"/static/favicon/wikipedia.ico\">\\n<link rel=\"license\" href=\"//creativecommons.org/licenses/by-sa/3.0/\">\\n<style>\\n.sprite{background-image:url(portal/wikipedia.org/assets/img/sprite-46c49284.png);background-image:linear-gradient(transparent,transparent),url(portal/wikipedia.org/assets/img/sprite-46c49284.svg);background-repeat:no-repeat;display:inline-block;vertical-align:middle}.svg-Commons-logo_sister{background-posit'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = soup.select(\"a strong\")\n",
    "len(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['English',\n",
       " '日本語',\n",
       " 'Deutsch',\n",
       " 'Español',\n",
       " 'Русский',\n",
       " 'Français',\n",
       " 'Italiano',\n",
       " '中文',\n",
       " 'Polski',\n",
       " 'Português']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.text.strip()for i in languages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 8 - A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url8 = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n<!DOCTYPE html>\\n<!--[if lt IE 9]><html class=\"lte-ie8\" lang=\"en\"><![endif]-->\\n<!--[if gt IE 8]><!--><html lang=\"en\"><!--<![endif]-->\\n<html class=\"govuk-template\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n    <title>Find open data - data.gov.uk</title>\\n\\n    <meta name=\"theme-color\" content=\"#0b0c0c\" />\\n\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n    \\n    <link rel=\"stylesheet\" media=\"screen\" href=\"/find-assets/application-f5e9f2f4ce27e6411457ec8df8d360010daa54eb6f37f2d7be3704208b1973f3.css\" />\\n    <meta name=\"csrf-param\" content=\"authenticity_token\" />\\n<meta name=\"csrf-token\" content=\"iCiTjqdaSVQm2q6YVLPr/9AXzwN6sJYXlbJ8ryJEkDh7OjjNH+YofzYY6PpnqphblHkFMYNW0/VwjAq+OOSM6Q==\" />\\n\\n    \\n  </head>\\n\\n  <body class=\"govuk-template__body\">\\n    <script>document.body.className = ((document.body.className) ? document.body.className + \\' js-enabled\\' : \\'js-enabled\\');</script>\\n\\n    <a class=\"gem-c-skip-link govuk-skip-link\" href=\"#main-content\">Skip to main content</a>\\n\\n\\n    \\n<'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = soup.select(\"h3 a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"govuk-link\" href=\"/search?filters%5Btopic%5D=Business+and+economy\">Business and economy</a>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Business and economy'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.text.strip()for i in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 9 - Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url9 = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>List of languages by number of native speakers - Wikipedia</title>\\n<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":!1,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"YA6@sApAMMUAAX0EheAAAACN\",\"wgCSPNonce\":!1,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":!1,\"wgNamespaceNumber\":0,\"wgPageName\":\"List_of_languages_by_number_of_native_speakers\",\"wgTitle\":\"List of languages by number of native speakers\",\"wgCurRevisionId\":999600491,\"wgRevisionId\":999600491,\"wgArticleId\":405385,\"wgIsArticle\":!0,\"wgIsRedirect\":!1,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Wikipedia indefinitely semi-protected pages\",\"Articles with short description\",\"Sho'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = soup.select(\"tbdoy, tr td a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mandarin Chinese'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mandarin Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Spanish',\n",
       " 'Indo-European',\n",
       " 'Romance',\n",
       " 'English',\n",
       " 'Indo-European',\n",
       " 'Germanic',\n",
       " 'Hindi',\n",
       " 'Hindustani',\n",
       " '[9]',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Bengali',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Portuguese',\n",
       " 'Indo-European',\n",
       " 'Romance',\n",
       " 'Russian',\n",
       " 'Indo-European',\n",
       " 'Balto-Slavic',\n",
       " 'Japanese',\n",
       " 'Japonic',\n",
       " 'Japanese',\n",
       " 'Western Punjabi',\n",
       " '[10]',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Marathi',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Telugu',\n",
       " 'Dravidian',\n",
       " 'South-Central',\n",
       " 'Wu Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Turkish',\n",
       " 'Turkic',\n",
       " 'Oghuz',\n",
       " 'Korean',\n",
       " 'Koreanic',\n",
       " 'language isolate',\n",
       " 'French',\n",
       " 'Indo-European',\n",
       " 'Romance',\n",
       " 'German',\n",
       " 'Standard German',\n",
       " 'Indo-European',\n",
       " 'Germanic',\n",
       " 'Vietnamese',\n",
       " 'Austroasiatic',\n",
       " 'Vietic',\n",
       " 'Tamil',\n",
       " 'Dravidian',\n",
       " 'South',\n",
       " 'Yue Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Urdu',\n",
       " 'Hindustani',\n",
       " '[9]',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Javanese',\n",
       " 'Austronesian',\n",
       " 'Malayo-Polynesian',\n",
       " 'Italian',\n",
       " 'Indo-European',\n",
       " 'Romance',\n",
       " 'Egyptian Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Gujarati',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Iranian Persian',\n",
       " 'Indo-European',\n",
       " 'Iranian',\n",
       " 'Bhojpuri',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Min Nan Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Hakka Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Jin Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Hausa',\n",
       " 'Afroasiatic',\n",
       " 'Chadic',\n",
       " 'Kannada',\n",
       " 'Dravidian',\n",
       " 'South',\n",
       " 'Indonesian',\n",
       " 'Malay',\n",
       " 'Austronesian',\n",
       " 'Malayo-Polynesian',\n",
       " 'Polish',\n",
       " 'Indo-European',\n",
       " 'Balto-Slavic',\n",
       " 'Yoruba',\n",
       " 'Niger–Congo',\n",
       " 'Volta–Niger',\n",
       " 'Xiang Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Malayalam',\n",
       " 'Dravidian',\n",
       " 'South',\n",
       " 'Odia',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Maithili',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Burmese',\n",
       " 'Sino-Tibetan',\n",
       " 'Lolo-Burmese',\n",
       " 'Eastern Punjabi',\n",
       " '[10]',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Sunda',\n",
       " 'Austronesian',\n",
       " 'Malayo-Polynesian',\n",
       " 'Sudanese Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Algerian Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Moroccan Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Ukrainian',\n",
       " 'Indo-European',\n",
       " 'Balto-Slavic',\n",
       " 'Igbo',\n",
       " 'Niger–Congo',\n",
       " 'Volta–Niger',\n",
       " 'Northern Uzbek',\n",
       " 'Turkic',\n",
       " 'Karluk',\n",
       " 'Sindhi',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'North Levantine Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Romanian',\n",
       " 'Indo-European',\n",
       " 'Romance',\n",
       " 'Tagalog',\n",
       " 'Austronesian',\n",
       " 'Malayo-Polynesian',\n",
       " 'Dutch',\n",
       " 'Indo-European',\n",
       " 'Germanic',\n",
       " 'Saʽidi Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Gan Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Amharic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Northern Pashto',\n",
       " 'Indo-European',\n",
       " 'Iranian',\n",
       " 'Magahi',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Thai',\n",
       " 'Kra–Dai',\n",
       " 'Tai',\n",
       " 'Saraiki',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Khmer',\n",
       " 'Austroasiatic',\n",
       " 'Khmer',\n",
       " 'Chhattisgarhi',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Somali',\n",
       " 'Afroasiatic',\n",
       " 'Cushitic',\n",
       " 'Malaysian',\n",
       " 'Malay',\n",
       " 'Austronesian',\n",
       " 'Malayo-Polynesian',\n",
       " 'Cebuano',\n",
       " 'Austronesian',\n",
       " 'Malayo-Polynesian',\n",
       " 'Nepali',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Mesopotamian Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Assamese',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Sinhalese',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Northern Kurdish',\n",
       " 'Indo-European',\n",
       " 'Iranian',\n",
       " 'Hejazi Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Nigerian Fulfulde',\n",
       " 'Niger–Congo',\n",
       " 'Senegambian',\n",
       " 'Bavarian',\n",
       " 'Indo-European',\n",
       " 'Germanic',\n",
       " 'South Azerbaijani',\n",
       " 'Turkic',\n",
       " 'Oghuz',\n",
       " 'Greek',\n",
       " 'Indo-European',\n",
       " 'Hellenic',\n",
       " 'Chittagonian',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Kazakh',\n",
       " 'Turkic',\n",
       " 'Kipchak',\n",
       " 'Deccan',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Hungarian',\n",
       " 'Uralic',\n",
       " 'Ugric',\n",
       " 'Kinyarwanda',\n",
       " 'Niger–Congo',\n",
       " 'Bantu',\n",
       " 'Zulu',\n",
       " 'Niger–Congo',\n",
       " 'Bantu',\n",
       " 'South Levantine Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Tunisian Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Sanaani Spoken Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Min Bei Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Southern Pashto',\n",
       " 'Indo-European',\n",
       " 'Iranian',\n",
       " 'Rundi',\n",
       " 'Niger–Congo',\n",
       " 'Bantu',\n",
       " 'Czech',\n",
       " 'Indo-European',\n",
       " 'Balto-Slavic',\n",
       " 'Taʽizzi-Adeni Arabic',\n",
       " 'Afroasiatic',\n",
       " 'Semitic',\n",
       " 'Uyghur',\n",
       " 'Turkic',\n",
       " 'Karluk',\n",
       " 'Min Dong Chinese',\n",
       " 'Sino-Tibetan',\n",
       " 'Sinitic',\n",
       " 'Sylheti',\n",
       " 'Indo-European',\n",
       " 'Indo-Aryan',\n",
       " 'Mandarin',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'Hindi',\n",
       " '[a]',\n",
       " 'Arabic',\n",
       " 'Portuguese',\n",
       " 'Bengali',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'Punjabi',\n",
       " 'German',\n",
       " 'Javanese',\n",
       " 'Wu',\n",
       " 'Shanghainese',\n",
       " 'Malay',\n",
       " 'Indonesian',\n",
       " 'Malaysian',\n",
       " 'Telugu',\n",
       " 'Vietnamese',\n",
       " 'Korean',\n",
       " 'French',\n",
       " 'Marathi',\n",
       " 'Tamil',\n",
       " 'Urdu',\n",
       " 'Turkish',\n",
       " 'Italian',\n",
       " 'Yue',\n",
       " 'Cantonese',\n",
       " 'Thai',\n",
       " 'Gujarati',\n",
       " 'Jin',\n",
       " 'Southern Min',\n",
       " 'Hokkien',\n",
       " 'Teochew',\n",
       " 'Persian',\n",
       " 'Polish',\n",
       " 'Pashto',\n",
       " 'Kannada',\n",
       " 'Xiang',\n",
       " 'Malayalam',\n",
       " 'Sundanese',\n",
       " 'Hausa',\n",
       " 'Odia',\n",
       " 'Burmese',\n",
       " 'Hakka',\n",
       " 'Ukrainian',\n",
       " 'Bhojpuri',\n",
       " '[b]',\n",
       " 'Tagalog',\n",
       " 'Filipino',\n",
       " 'Yoruba',\n",
       " 'Maithili',\n",
       " '[b]',\n",
       " 'Uzbek',\n",
       " 'Sindhi',\n",
       " 'Amharic',\n",
       " 'Fula',\n",
       " 'Romanian',\n",
       " 'Oromo',\n",
       " 'Igbo',\n",
       " 'Azerbaijani',\n",
       " 'Awadhi',\n",
       " '[b]',\n",
       " 'Gan',\n",
       " 'Cebuano',\n",
       " 'Dutch',\n",
       " 'Kurdish',\n",
       " 'Serbo-Croatian',\n",
       " 'Malagasy',\n",
       " 'Saraiki',\n",
       " '[c]',\n",
       " 'Nepali',\n",
       " 'Sinhala',\n",
       " 'Chittagonian',\n",
       " 'Zhuang',\n",
       " 'Khmer',\n",
       " 'Turkmen',\n",
       " 'Assamese',\n",
       " 'Madurese',\n",
       " 'Somali',\n",
       " 'Marwari',\n",
       " '[b]',\n",
       " 'Magahi',\n",
       " '[b]',\n",
       " 'Haryanvi',\n",
       " '[b]',\n",
       " 'Hungarian',\n",
       " 'Chhattisgarhi',\n",
       " '[b]',\n",
       " 'Greek',\n",
       " 'Chewa',\n",
       " 'Deccan',\n",
       " 'Akan',\n",
       " 'Kazakh',\n",
       " 'Northern Min',\n",
       " 'disputed',\n",
       " 'discuss',\n",
       " 'Sylheti',\n",
       " 'Zulu',\n",
       " 'Czech',\n",
       " 'Kinyarwanda',\n",
       " 'Dhundhari',\n",
       " '[b]',\n",
       " 'Haitian Creole',\n",
       " 'Eastern Min',\n",
       " 'Fuzhou dialect',\n",
       " 'Ilocano',\n",
       " 'Quechua',\n",
       " 'Kirundi',\n",
       " 'Swedish',\n",
       " 'Hmong',\n",
       " 'Shona',\n",
       " 'Uyghur',\n",
       " 'Hiligaynon/Ilonggo',\n",
       " 'Mossi',\n",
       " 'Xhosa',\n",
       " 'Belarusian',\n",
       " '[d]',\n",
       " 'Balochi',\n",
       " 'Konkani',\n",
       " 'Countries by spoken languages',\n",
       " 'Official',\n",
       " 'Countries by the number of recognized official languages',\n",
       " 'Arabic',\n",
       " 'Chinese',\n",
       " 'Dutch/Afrikaans',\n",
       " 'English',\n",
       " 'French',\n",
       " 'German',\n",
       " 'Hindustani',\n",
       " 'Italian',\n",
       " 'Malay',\n",
       " 'Persian',\n",
       " 'Portuguese',\n",
       " 'Romanian',\n",
       " 'Russian',\n",
       " 'Spanish',\n",
       " 'Tamil',\n",
       " 'Endonyms',\n",
       " 'Countries and capitals in native languages',\n",
       " 'Exonyms',\n",
       " 'Country names in various languages',\n",
       " 'A–C',\n",
       " 'D–I',\n",
       " 'J–P',\n",
       " 'Q–Z',\n",
       " 'China',\n",
       " 'Germany',\n",
       " 'Iceland',\n",
       " 'India',\n",
       " 'Indonesia',\n",
       " 'Japan',\n",
       " 'Korea',\n",
       " 'Kosovo',\n",
       " 'Myanmar',\n",
       " 'Singapore',\n",
       " 'Sri Lanka',\n",
       " 'Vietnam',\n",
       " 'Languages of the European Union',\n",
       " 'Africa',\n",
       " 'Americas',\n",
       " 'North',\n",
       " 'South',\n",
       " 'Asia',\n",
       " 'East',\n",
       " 'South',\n",
       " 'Europe',\n",
       " 'Oceania',\n",
       " 'Official languages',\n",
       " 'by state',\n",
       " 'List of languages without official status',\n",
       " 'Countries by the number of recognized official languages',\n",
       " 'Languages by the number of countries in which they are recognized as an official language',\n",
       " 'Number of languages',\n",
       " 'By number of native speakers',\n",
       " 'By number of total speakers',\n",
       " 'Languages in censuses',\n",
       " 'family',\n",
       " 'Language families',\n",
       " 'List of Afro-Asiatic languages',\n",
       " 'List of Austronesian languages',\n",
       " 'List of Indo-European languages',\n",
       " 'List of Mongolic languages',\n",
       " 'List of Tungusic languages',\n",
       " 'List of Turkic languages',\n",
       " 'List of Uralic languages',\n",
       " 'geopolitical',\n",
       " 'Arab League (Arabic)',\n",
       " 'Dutch Language Union (Dutch)',\n",
       " 'Francophonie (French)',\n",
       " 'Community of Portuguese Language Countries (Portuguese)',\n",
       " 'Países Africanos de Língua Oficial Portuguesa (Portuguese)',\n",
       " 'Latin Union',\n",
       " 'Romance',\n",
       " 'Hispanidad (Spanish)',\n",
       " 'Turkic Council',\n",
       " 'Turkic',\n",
       " 'International Organization of Turkic Culture',\n",
       " 'Turkic',\n",
       " 'Three Linguistic Spaces (French, Portuguese and Spanish)',\n",
       " 'Lists of languages',\n",
       " 'Category:Languages']"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.text.strip()for i in top10] # no es lo que se pide.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping up the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Challenge 10 - The 20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url10 = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 11 - IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 12 - Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 13 - Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(city):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 14 - Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did you limit your output? Thank you! 🙂**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
